{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp2e9Di21HfZuZjP5ChdmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seschm/Internship-Gaertner/blob/main/Relevant_NN_for_IC_POVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXYmli11Towu"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.scipy as jsp\n",
        "from jax import jit, vmap, pmap, grad\n",
        "from jax import random\n",
        "import flax\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "import torch.utils.data as data\n",
        "from functools import partial\n",
        "\n",
        "import itertools\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import random as rng\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from numpy import sqrt, cos, sin, exp, pi, log2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import unitary_group\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_pure_state(nQubit):\n",
        "    \"\"\"\n",
        "    Generates Haar random pure state.\n",
        "    To generate a random pure state, take any basis state, e.g. |00...00>\n",
        "    and apply a random unitary matrix. For consistency each basis state should be the same.\n",
        "    \"\"\"\n",
        "    baseRho=np.zeros((2**nQubit,2**nQubit),dtype=complex)\n",
        "    baseRho[0,0]=1\n",
        "    U=unitary_group.rvs(2**nQubit)\n",
        "    return U@baseRho@U.conj().T"
      ],
      "metadata": {
        "id": "9JkKa3AgTp6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_single_qubit(theta,phi):\n",
        "    \"\"\"\n",
        "    Generates single qubit out of the given angles theta and phi.\n",
        "    First construct the single qubit state as an array of shape (2, 1).\n",
        "    Then compute the matrixproduct with its adjoint state.\n",
        "    \"\"\"\n",
        "    state = np.array([[cos(theta/2)],[sin(theta/2)*exp(phi*1.j)]])\n",
        "    return state@state.conj().T"
      ],
      "metadata": {
        "id": "56QOrZ6ITr0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_seperable_pure_state(nQubit):\n",
        "    \"\"\"\n",
        "    Generates random seperable pure state.\n",
        "    First generate the desired number of random pure states.\n",
        "    Then tensor them together.\n",
        "    \"\"\"\n",
        "    single_qubits = []\n",
        "    for i in range(0,nQubit):\n",
        "        single_qubits.append(generate_random_pure_state(1))\n",
        "    tensored_qubits = [single_qubits[0]]\n",
        "    for i in range(1,nQubit):\n",
        "        tensored_qubits.append(np.kron(tensored_qubits[-1],single_qubits[i]))\n",
        "    return tensored_qubits[-1]"
      ],
      "metadata": {
        "id": "gt1-_gEcTus8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def depolarizing_channel(state,p):\n",
        "    \"\"\"\n",
        "    Applies a depolarizing channel to the given state with p the probability of the completely mixed state.\n",
        "    \"\"\"\n",
        "    d=len(state[0])\n",
        "    return p*np.eye(d)/d+(1-p)*state"
      ],
      "metadata": {
        "id": "O6ox4KjPTw5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_POVM(theta,phi,nQubit):\n",
        "    \"\"\"\n",
        "    Generates a POVM consisting of multi qubit projectors on to the axis defined by the two angles theta and phi.\n",
        "    First generates all possible states (combinations of spin up and down) as strings containing 1s and 0s.\n",
        "    The order is equal to binary counting.\n",
        "    Then generates the single qubit projector and its orthogonal projector.\n",
        "    In the next step all single qubit projectors corresponding to the same state are gathered in the correct order and then tensored together to get an element of the POVM.\n",
        "    Returns the POVM with the elements beeing ordered equal to binary counting (-> up ... up, up ... up down, up ... up down up, ...).\n",
        "    \"\"\"\n",
        "    up_and_downs = []\n",
        "\n",
        "    for i in range(2**nQubit):\n",
        "        binary = bin(i)[2:]\n",
        "        zeros = np.zeros(nQubit-len(binary), dtype=int)\n",
        "        for k in range(nQubit-len(binary)):\n",
        "            binary = '0' + binary\n",
        "        up_and_downs.append(binary)\n",
        "\n",
        "    projector=generate_single_qubit(theta,phi)\n",
        "    orthogonal_projector = np.eye(2)-projector\n",
        "    POVM = []\n",
        "\n",
        "    for i in range(2**nQubit):\n",
        "        tensored_projector = []\n",
        "        single_projectors = []\n",
        "        for j in range(nQubit):\n",
        "            if up_and_downs[i][j] == '0':\n",
        "                single_projectors.append(projector)\n",
        "            if up_and_downs[i][j] == '1':\n",
        "                single_projectors.append(orthogonal_projector)\n",
        "        tensored_projector.append(single_projectors[0])\n",
        "        for k in range(nQubit-1):\n",
        "            tensored_projector.append(np.kron(tensored_projector[-1],single_projectors[k+1]))\n",
        "        POVM.append(tensored_projector[-1])\n",
        "\n",
        "    return POVM"
      ],
      "metadata": {
        "id": "IpUOIzkPT0QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_pauli6(nQubits):\n",
        "    \"\"\"\n",
        "    Generates the Pauli 6 for n qubits.\n",
        "    First define the Pauli 6 for a single qubit.\n",
        "    Then determine all possible combinations of the Pauli 6 matrices for the given qubit number.\n",
        "    Then tensor all combinations together.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define Pauli 6 for single qubit\n",
        "    X_plus = generate_single_qubit(pi/2,0)\n",
        "    X_minus = np.eye(2)-X_plus\n",
        "    Y_plus = generate_single_qubit(pi/2,pi/2)\n",
        "    Y_minus = np.eye(2)-Y_plus\n",
        "    Z_plus = generate_single_qubit(0,0)\n",
        "    Z_minus = np.eye(2)-Z_plus\n",
        "\n",
        "    # Create lists to iter through\n",
        "    paulis = [X_plus,X_minus,Y_plus,Y_minus,Z_plus,Z_minus]\n",
        "    indices = [0,1,2,3,4,5]\n",
        "    ref_list_temp = []\n",
        "\n",
        "    # Determine all possible combinations of the indices in the list \"indices\" with the length nQubits\n",
        "    for comb in itertools.combinations_with_replacement(indices, nQubits):\n",
        "        # Generate all permutations of the combination\n",
        "        for perm in itertools.permutations(comb):\n",
        "            ref_list_temp.append(perm)\n",
        "\n",
        "    ref_list = list(dict.fromkeys(ref_list_temp))\n",
        "    POVM = []\n",
        "\n",
        "    # For all the possible index combinations tensor the coresponding Pauli matrices together\n",
        "    for index, comb in enumerate(ref_list):\n",
        "        POVM.append(paulis[comb[0]])\n",
        "        for i in range(1,nQubits):\n",
        "            POVM[index] = np.kron(POVM[index],paulis[comb[i]])\n",
        "\n",
        "    return POVM"
      ],
      "metadata": {
        "id": "CpRobvGuT3am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_multi_qubit_measurement(state,POVM):\n",
        "    \"\"\"\n",
        "    Performs a multi qubit measurement with the given POVM.\n",
        "    \"\"\"\n",
        "    probabilities = np.einsum('lii->l',np.einsum('ij,ljk->lik',state,POVM))\n",
        "    return probabilities"
      ],
      "metadata": {
        "id": "H_9mm0joRCKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_noisy_multi_qubit_measurement(state,POVM,p):\n",
        "    \"\"\"\n",
        "    Generates probabilities of the noisy state.\n",
        "    First applies the noise, then generates the probabilities.\n",
        "    \"\"\"\n",
        "    noisy_state = depolarizing_channel(state,p)\n",
        "    return perform_multi_qubit_measurement(noisy_state,POVM)"
      ],
      "metadata": {
        "id": "KCTuAGeVT5fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cholesky_decomposition(state):\n",
        "    \"\"\"\n",
        "    Determines the cholesky decomposition for the given state.\n",
        "    (Better to use np.linalg.cholesky(state))\n",
        "    \"\"\"\n",
        "    n = len(state)\n",
        "    A = np.zeros_like(state)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i+1):\n",
        "            if i == j:\n",
        "                A[i][j] = np.sqrt(state[i][i] - np.sum(A[i][:j]**2))\n",
        "            else:\n",
        "                A[i][j] = (state[i][j] - np.sum(A[i][:j]*A[j][:j])) / A[j][j]\n",
        "\n",
        "    return A"
      ],
      "metadata": {
        "id": "e3-pm8l1T8YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(probabilities,samplesize):\n",
        "    \"\"\"\n",
        "    Takes in a probability distribution and samples from it.\n",
        "    \"\"\"\n",
        "    sampling = rng.choices(np.arange(0,len(probabilities)), weights=probabilities, k=samplesize)\n",
        "    sampled_probabilities = []\n",
        "    for element in np.arange(0,len(probabilities)):\n",
        "        sampled_probabilities.append(sampling.count(element)/samplesize)\n",
        "    return sampled_probabilities"
      ],
      "metadata": {
        "id": "XNLJ3mDIT97P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@partial(jit,static_argnums=(4,5))  # Jit the function for efficiency\n",
        "def loss_fn(state, params, batch_input, batch_target_output,nQubits,batch_size):\n",
        "    \"\"\"\n",
        "    Determines the quantum infidelity as loss (code only works for pure states as target output values).\n",
        "    Therefore the output is used to get the cholesky coefficients.\n",
        "      First run the given batch for the current weights and biases (params) through the NN.\n",
        "      Then reshape these predictions in 2^n x 2^n matrices (do that for each state of the batch).\n",
        "      Then add the transposed of this matrix times i to this matrix.\n",
        "      Set all elements in the upper triangular to zero, by multiplying this matrix with a lower triangular matrix (all non-zero elements are ones) elementwise.\n",
        "      Discard the imaginary part of the diagonal elements.\n",
        "    From the cholesky decompostion the density matrix is calculated: rho = A*A^dagger / trace(A*A^dagger)\n",
        "    Calculate the quantum infidelty for this density matrix and the desired non-noisy density matrix (which is a pure state).\n",
        "    \"\"\"\n",
        "    pred = state.apply_fn(params, batch_input)\n",
        "\n",
        "    B = jnp.reshape(jnp.asarray(pred),(batch_size,2**nQubits,2**nQubits))\n",
        "    #C = jnp.einsum('ijk,ilk->ijl',B,1.j*B)\n",
        "    O = jnp.einsum('ijk->ikj',B)\n",
        "    C = B + 1.j*O\n",
        "    Tri = jnp.tril(jnp.ones((batch_size,2**nQubits,2**nQubits)))\n",
        "    D = jnp.multiply(C,Tri)\n",
        "    Re_Diag = jnp.real(jnp.diagonal(D, axis1=-2, axis2=-1))\n",
        "    A = jnp.copy(D)\n",
        "    A = A.at[..., jnp.arange(2**nQubits), jnp.arange(2**nQubits)].set(Re_Diag)\n",
        "\n",
        "    #A = jnp.zeros((batch_size,2**nQubits,2**nQubits), dtype=complex)\n",
        "    #for k in range(batch_size):            # state\n",
        "    #    counter = 0\n",
        "    #    for j in range(2**nQubits):        # row\n",
        "    #        for i in range(2**nQubits):    # column\n",
        "    #            if i < j:\n",
        "    #                A = A.at[k,j,i].set(pred[k,counter]+pred[k,counter+1]*1.j)\n",
        "    #                counter += 2\n",
        "    #            if i == j:\n",
        "    #                A = A.at[k,j,i].set(pred[k,counter])\n",
        "    #                counter += 1\n",
        "    pred_den_unn = jnp.einsum('ijk,ilk->ijl',A,A.conj())\n",
        "    trace_inv = 1/ jnp.trace(pred_den_unn,axis1=1,axis2=2)\n",
        "    pred_den = jnp.einsum('ijk,i->ijk',pred_den_unn,trace_inv)\n",
        "    matrix_product = jnp.einsum('ijk,ikl->ijl',pred_den,batch_target_output)\n",
        "    loss = jnp.mean(1-jnp.trace(matrix_product,axis1=1,axis2=2))\n",
        "    return jax.lax.real(loss)"
      ],
      "metadata": {
        "id": "wZmAat6CUAgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@partial(jit,static_argnums=(3,4))  # Jit the function for efficiency\n",
        "def train_step(state, batch_input, batch_target_output,nQubit,batch_size):\n",
        "    \"\"\"\n",
        "    Performs one training step of the network and returns the updated weights and biases (contained in state)\n",
        "    \"\"\"\n",
        "    # Gradient function\n",
        "    grad_fn = jax.value_and_grad(loss_fn,# Function to calculate the loss\n",
        "                                 argnums=1,  # Parameters are second argument of the function\n",
        "                                )\n",
        "    # Determine gradients for current model, parameters and batch\n",
        "    loss, grads = grad_fn(state, state.params, batch_input, batch_target_output,nQubit,batch_size)\n",
        "    # Perform parameter update with gradients and optimizer\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    # Return state and any other value we might want\n",
        "    return state, loss"
      ],
      "metadata": {
        "id": "1r58-J7RUCpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(state, batched_training_input, batched_training_target_outputs, acc_input, acc_target_output, batched_te_unm_den,nQubits,batch_size, num_epochs = 100):\n",
        "  \"\"\"\n",
        "  Trains the network for num_epochs epochs.\n",
        "  Also calculates the different accuracies after each training step.\n",
        "  \"\"\"\n",
        "\n",
        "  # Lists to be filled with the accuracy of the test, training and unmitigated data\n",
        "  # The accuracy in this case equals the loss, so it's the quantum infidelity\n",
        "  acc = []\n",
        "  acc_train = []\n",
        "  acc_unmit = []\n",
        "\n",
        "\n",
        "  # for each epoch updates the paramters for each batch of the training data\n",
        "  for epoch in tqdm(range(num_epochs)):\n",
        "    acc_train_temp = []\n",
        "    acc_temp = []\n",
        "    acc_unmit_temp = []\n",
        "    # Updating the parameters for each batch\n",
        "    for i in range(len(batched_training_input)):\n",
        "        state, loss = train_step(state, batched_training_input[i], batched_training_target_outputs[i],nQubits,batch_size)\n",
        "    # Calculating the accuracy for the batches of the training data\n",
        "    for i in range(len(batched_training_input)):\n",
        "        acc_train_temp.append(loss_fn(state,state.params,batched_training_input[i], batched_training_target_outputs[i],nQubits,batch_size))\n",
        "    # Calculating the accuracy for the test and unmitigated data\n",
        "    for j in range(len(acc_input)):\n",
        "        acc_temp.append(loss_fn(state,state.params,acc_input[j], acc_target_output[j],nQubits,batch_size))\n",
        "        matrix_product = jnp.einsum('ijk,ikl->ijl',batched_te_unm_den[j],acc_target_output[j])\n",
        "        acc_unmit_temp.append(1-jnp.trace(matrix_product))\n",
        "    # Calculating the mean accuracy over all batches\n",
        "    acc_train.append(jnp.mean(jnp.asarray(acc_train_temp)))\n",
        "    acc.append(jnp.mean(jnp.asarray(acc_temp)))\n",
        "    acc_unmit.append(jnp.mean(jnp.asarray(acc_unmit_temp)))\n",
        "\n",
        "  return state, acc, acc_train, acc_unmit"
      ],
      "metadata": {
        "id": "KmZ3CCYPUEhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_along_axis0(arr):\n",
        "    \"\"\"\n",
        "    Shuffles an array along the axis 0.\n",
        "    \"\"\"\n",
        "    rng_key = jax.random.PRNGKey(0)  # Initialize random number generator key\n",
        "    permuted_indices = jax.random.permutation(rng_key, arr.shape[0])\n",
        "    shuffled_arr = jnp.take(arr, permuted_indices, axis=0)\n",
        "    return shuffled_arr"
      ],
      "metadata": {
        "id": "AAhpShJEUfFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  \"\"\"\n",
        "  Defining features of the network (e.g. activation function)\n",
        "  \"\"\"\n",
        "  num_neurons_per_layer : list[int]   # List containing the number of neurons per layer (except input layer)\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    activation = x\n",
        "    for i, numb_neurons in enumerate(self.num_neurons_per_layer):\n",
        "      activation = nn.Dense(numb_neurons)(activation)\n",
        "      if i != len(self.num_neurons_per_layer) - 1:\n",
        "        activation = nn.relu(activation) # using a relu activation function for all but the last layer\n",
        "\n",
        "    return activation"
      ],
      "metadata": {
        "id": "Shc3Be_d2q83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set all variables that need to be preselected\n",
        "nQubit_list = [2,3,4,5]\n",
        "training_states_list = [2500,5000,10000,12500]\n",
        "num_epochs = 300\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "test_states = 200\n",
        "theta = 0\n",
        "phi = 0\n",
        "p = 0.15\n",
        "samplesize = 10000\n",
        "\n",
        "# Lists for storing the accuracies\n",
        "acc_test_list = []\n",
        "acc_train_list = []\n",
        "acc_unmit_list = []\n",
        "\n",
        "for i in range(0,4):\n",
        "    nQubit = nQubit_list[i]\n",
        "    layers_list = [[20,20,20,20,20,4**nQubit],[40,40,4**nQubit],[80,80,80,80,80,80,80,4**nQubit],[160,160,160,160,160,4**nQubit]]\n",
        "    layers = layers_list[i]\n",
        "    training_states = training_states_list[i]\n",
        "\n",
        "    model = MLP(num_neurons_per_layer=layers)                                                     # Initialize network\n",
        "    x_key, init_key = random.split(random.PRNGKey(0))\n",
        "    x = random.normal(x_key, (batch_size, 6**nQubit))                                             # Batch size 100, input size 2\n",
        "    params = model.init(init_key, x)                                                              # Initialize network params (biases being initialized as zeros)\n",
        "    optimizer = optax.adam(learning_rate=learning_rate)                                           # selecting an optimizer with a certain learning rate\n",
        "    # Not exactly sure how train_state modul works\n",
        "    # a train state contains the current parameters (weights, biases) and the optimizer\n",
        "    model_state = train_state.TrainState.create(apply_fn=model.apply,params=params,tx=optimizer)\n",
        "\n",
        "    POVM = generate_pauli6(nQubit)                                            # Generating Pauli 6 for the given Qubit number\n",
        "\n",
        "    # Lists for storing generated data\n",
        "    training_probs = []\n",
        "    training_den = []\n",
        "    test_probs = []\n",
        "    test_unm_den = []\n",
        "    test_den = []\n",
        "\n",
        "    # Generating training data\n",
        "    for i in tqdm(range(training_states)):\n",
        "        state = generate_random_seperable_pure_state(nQubit)\n",
        "        training_den.append(state)\n",
        "        noisy_probs = perform_noisy_multi_qubit_measurement(state,POVM,p)\n",
        "        # training_probs.append(noisy_probs)                                  # -> used if no sampling is needed\n",
        "        noisy_probs_sampled = sampling(noisy_probs,samplesize)\n",
        "        training_probs.append(noisy_probs_sampled)\n",
        "\n",
        "    # Generating test data\n",
        "    for i in tqdm(range(test_states)):\n",
        "        state = generate_random_seperable_pure_state(nQubit)\n",
        "        test_den.append(state)\n",
        "        noisy_state = depolarizing_channel(state,p)\n",
        "        test_unm_den.append(noisy_state)\n",
        "        noisy_probs = perform_noisy_multi_qubit_measurement(state,POVM,p)\n",
        "        # test_probs.append(noisy_probs)                                      # -> used if no sampling is needed\n",
        "        noisy_probs_sampled = sampling(noisy_probs,samplesize)\n",
        "        test_probs.append(noisy_probs_sampled)\n",
        "\n",
        "    # Shuffle the generated data (shouldn't be necessary)\n",
        "    training_probs_shuf = shuffle_along_axis0(jnp.asarray(training_probs))\n",
        "    training_As_shuf = shuffle_along_axis0(jnp.asarray(training_den))\n",
        "    test_probs_shuf = shuffle_along_axis0(jnp.asarray(test_probs))\n",
        "    test_As_shuf = shuffle_along_axis0(jnp.asarray(test_den))\n",
        "    test_unm_As_shuf = shuffle_along_axis0(jnp.asarray(test_unm_den))\n",
        "\n",
        "    # batching the generated data\n",
        "    batched_tr_probs = jnp.split(training_probs_shuf,int(len(training_probs_shuf)/batch_size),axis=0)\n",
        "    batched_tr_As = jnp.split(training_As_shuf,int(len(training_As_shuf)/batch_size),axis=0)\n",
        "    batched_te_probs = jnp.split(test_probs_shuf,int(len(test_probs_shuf)/batch_size),axis=0)\n",
        "    batched_te_As = jnp.split(test_As_shuf ,int(len(test_As_shuf)/batch_size),axis=0)\n",
        "    batched_te_unm_As = jnp.split(test_unm_As_shuf ,int(len(test_unm_As_shuf)/batch_size),axis=0)\n",
        "\n",
        "    # Training the NN\n",
        "    state, acc, acc_train, acc_unmit = train_model(model_state, jnp.asarray(batched_tr_probs), jnp.asarray(batched_tr_As),\n",
        "                                                               jnp.asarray(batched_te_probs), jnp.asarray(batched_te_As),\n",
        "                                                               jnp.asarray(batched_te_unm_As),\n",
        "                                                              nQubits=nQubit,batch_size=batch_size, num_epochs = num_epochs)\n",
        "    # Saving the accuracies\n",
        "    acc_test_list.append(acc)\n",
        "    acc_train_list.append(acc_train)\n",
        "    acc_unmit_list.append(acc_unmit)"
      ],
      "metadata": {
        "id": "unNzeJHFH-8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the NN accurcies over the number of epochs\n",
        "i = np.arange(0,num_epochs)\n",
        "\n",
        "for j in range(0,4)\n",
        "    fig, ax = plt.subplots(figsize=(18, 6))\n",
        "    ax.plot(i,acc_test_list[j],label=\"test data\",linestyle=\"--\",color=\"red\")\n",
        "    ax.plot(i,acc_train_list[j],label=\"training data\",linestyle=\"--\",color=\"black\")\n",
        "    ax.plot(i,acc_unmit_list[j],label=\"unmittigated data\",linestyle=\"--\",color=\"blue\")\n",
        "    ax.set_xlabel('Number of epochs')\n",
        "    ax.set_ylabel('Accuracy / quantum infidelity')\n",
        "    ax.set_yscale('log')\n",
        "    ax.legend()\n",
        "    fig.suptitle('Accuracy')"
      ],
      "metadata": {
        "id": "cZEGOwliM_5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the results\n",
        "labels = [\"2 Qubits\",\"3 Qubits\",\"4 Qubits\",\"5 Qubits\"]\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "ax.bar(0,acc_test_list[0][-1],label=\"test data\",color=\"blue\")\n",
        "ax.bar(1,acc_train_list[0][-1],label=\"training data\",color=\"red\")\n",
        "ax.bar(2,acc_unmit_list[0][-1],label=\"unmitigated test data\",color=\"black\")\n",
        "ax.bar(5,acc_test_list[1][-1],color=\"blue\")\n",
        "ax.bar(6,acc_train_list[1][-1],color=\"red\")\n",
        "ax.bar(7,acc_unmit_list[1][-1],color=\"black\")\n",
        "ax.bar(10,acc_test_list[2][-1],color=\"blue\")\n",
        "ax.bar(11,acc_train_list[2][-1],color=\"red\")\n",
        "ax.bar(12,acc_unmit_list[2][-1],color=\"black\")\n",
        "ax.bar(15,acc_test_list[3][-1],color=\"blue\")\n",
        "ax.bar(16,acc_train_list[3][-1],color=\"red\")\n",
        "ax.bar(17,acc_unmit_list[3][-1],color=\"black\")\n",
        "ax.set_xticks([1,6,11,16])\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_yscale('log')\n",
        "ax.set_xlabel(\"\")\n",
        "ax.set_ylabel(\"accuracy / quantum infidelity\")\n",
        "ax.legend()\n",
        "\n",
        "fig.suptitle('NN for IC-POVM')"
      ],
      "metadata": {
        "id": "R3BRzPSZNoHw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}